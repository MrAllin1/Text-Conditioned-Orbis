=== Starting SLURM Job on lmbhiwi_gpu-rtx2080 ===
Node: dagobert
Job ID: 26967152
Python = /work/dlclarge2/alidemaa-text-control-orbis/miniconda3/envs/orbis_env/bin/python
Torch CUDA available?:
True
Sun Dec  7 02:22:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:1A:00.0 Off |                  N/A |
| 22%   28C    P8             17W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:B1:00.0 Off |                  N/A |
| 22%   26C    P8              1W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:B2:00.0 Off |                  N/A |
| 22%   26C    P8             52W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.
Using device: cuda
Loading FM config from: /work/dlclarge2/alidemaa-text-control-orbis/orbis/finetuning/stage2_baseline_covla_bev.yaml
Train dataset target from YAML: data.covla_dataset.CoVLAOrbisMultiFrame
YAML data params (train / CoVLA):
  size            = [192, 336]
  num_frames      = 6
  stored_rate     = 20
  target_rate     = 5
  scale_min/max   = 0.75, 1.0
  captions_dir    = /work/dlclarge2/alidemaa-text-control-orbis/orbis/data/covla_captions
  videos_dir      = /work/dlclarge2/alidemaa-text-control-orbis/orbis/data/covla_100_videos
Text encoder initialized & frozen.

Loading tokenizer from stage1 config...
VQLPIPSWithDiscriminator initialized with hinge loss.
Tokenizer ready.

Loading STDiT (world model)...
DEBUG: final_layer.linear mean abs BEFORE ckpt load: 0.0
DEBUG: final_layer.linear mean abs AFTER ckpt load: 0.0
STDiT pretrained weights loaded (strict=False).

DEBUG: Trainable parameters in STDiT + text proj:
  TRAINABLE: pos_embed torch.Size([1, 252, 768])
  TRAINABLE: frame_emb torch.Size([1, 6, 1, 768])
  TRAINABLE: x_embedder.proj.weight torch.Size([768, 16, 1, 1])
  TRAINABLE: x_embedder.proj.bias torch.Size([768])
  TRAINABLE: t_embedder.mlp.0.weight torch.Size([768, 256])
  TRAINABLE: t_embedder.mlp.0.bias torch.Size([768])
  TRAINABLE: t_embedder.mlp.2.weight torch.Size([768, 768])
  TRAINABLE: t_embedder.mlp.2.bias torch.Size([768])
  TRAINABLE: text_mlp.1.weight torch.Size([768, 768])
  TRAINABLE: text_mlp.1.bias torch.Size([768])
  TRAINABLE: blocks.0.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.0.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.0.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.0.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.0.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.0.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.0.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.0.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.0.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.0.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.0.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.0.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.0.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.0.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.0.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.0.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.0.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.0.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.0.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.0.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.0.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.0.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.0.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.0.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.0.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.0.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.1.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.1.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.1.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.1.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.1.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.1.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.1.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.1.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.1.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.1.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.1.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.1.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.1.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.1.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.1.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.1.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.1.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.1.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.1.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.1.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.1.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.1.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.1.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.1.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.1.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.1.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.2.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.2.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.2.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.2.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.2.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.2.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.2.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.2.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.2.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.2.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.2.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.2.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.2.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.2.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.2.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.2.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.2.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.2.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.2.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.2.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.2.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.2.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.2.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.2.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.2.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.2.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.3.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.3.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.3.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.3.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.3.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.3.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.3.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.3.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.3.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.3.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.3.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.3.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.3.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.3.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.3.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.3.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.3.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.3.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.3.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.3.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.3.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.3.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.3.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.3.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.3.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.3.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.4.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.4.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.4.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.4.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.4.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.4.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.4.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.4.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.4.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.4.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.4.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.4.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.4.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.4.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.4.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.4.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.4.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.4.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.4.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.4.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.4.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.4.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.4.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.4.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.4.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.4.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.5.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.5.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.5.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.5.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.5.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.5.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.5.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.5.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.5.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.5.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.5.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.5.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.5.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.5.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.5.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.5.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.5.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.5.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.5.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.5.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.5.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.5.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.5.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.5.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.5.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.5.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.6.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.6.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.6.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.6.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.6.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.6.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.6.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.6.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.6.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.6.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.6.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.6.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.6.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.6.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.6.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.6.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.6.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.6.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.6.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.6.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.6.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.6.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.6.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.6.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.6.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.6.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.7.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.7.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.7.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.7.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.7.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.7.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.7.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.7.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.7.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.7.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.7.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.7.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.7.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.7.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.7.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.7.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.7.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.7.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.7.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.7.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.7.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.7.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.7.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.7.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.7.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.7.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.8.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.8.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.8.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.8.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.8.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.8.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.8.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.8.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.8.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.8.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.8.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.8.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.8.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.8.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.8.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.8.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.8.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.8.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.8.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.8.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.8.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.8.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.8.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.8.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.8.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.8.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.9.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.9.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.9.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.9.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.9.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.9.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.9.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.9.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.9.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.9.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.9.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.9.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.9.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.9.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.9.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.9.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.9.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.9.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.9.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.9.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.9.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.9.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.9.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.9.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.9.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.9.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.10.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.10.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.10.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.10.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.10.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.10.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.10.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.10.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.10.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.10.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.10.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.10.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.10.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.10.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.10.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.10.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.10.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.10.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.10.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.10.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.10.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.10.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.10.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.10.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.10.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.10.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: blocks.11.space_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.11.space_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.11.space_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.11.space_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.11.space_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.11.space_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.11.space_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.11.space_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.11.time_attn.qkv.weight torch.Size([2304, 768])
  TRAINABLE: blocks.11.time_attn.qkv.bias torch.Size([2304])
  TRAINABLE: blocks.11.time_attn.q_norm.weight torch.Size([64])
  TRAINABLE: blocks.11.time_attn.q_norm.bias torch.Size([64])
  TRAINABLE: blocks.11.time_attn.k_norm.weight torch.Size([64])
  TRAINABLE: blocks.11.time_attn.k_norm.bias torch.Size([64])
  TRAINABLE: blocks.11.time_attn.proj.weight torch.Size([768, 768])
  TRAINABLE: blocks.11.time_attn.proj.bias torch.Size([768])
  TRAINABLE: blocks.11.space_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.11.space_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.11.space_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.11.space_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.11.time_mlp.fc1.weight torch.Size([3072, 768])
  TRAINABLE: blocks.11.time_mlp.fc1.bias torch.Size([3072])
  TRAINABLE: blocks.11.time_mlp.fc2.weight torch.Size([768, 3072])
  TRAINABLE: blocks.11.time_mlp.fc2.bias torch.Size([768])
  TRAINABLE: blocks.11.adaLN_modulation.1.weight torch.Size([6912, 768])
  TRAINABLE: blocks.11.adaLN_modulation.1.bias torch.Size([6912])
  TRAINABLE: final_layer.linear.weight torch.Size([16, 768])
  TRAINABLE: final_layer.linear.bias torch.Size([16])
  TRAINABLE: final_layer.adaLN_modulation.1.weight torch.Size([1536, 768])
  TRAINABLE: final_layer.adaLN_modulation.1.bias torch.Size([1536])
Total trainable STDiT params: 236608528
Total trainable text_proj params: 393984
Total trainable params (all): 237002512
[CKPT] No existing checkpoint found → starting from scratch

Starting AdaLN DEBUG fine-tuning (2 epochs, 20 steps)...

[TRAIN] Starting epoch 1/2
DEBUG: loss on first step: 0.9808831810951233
DEBUG: first trainable grad mean abs: pos_embed 0.0
Epoch 0 finished — avg_loss=0.8898
[CKPT] Saved checkpoint at epoch=0, step=19
[TRAIN] Starting epoch 2/2
Epoch 1 finished — avg_loss=0.4755
[CKPT] Saved checkpoint at epoch=1, step=19

Done! DEBUG AdaLN fine-tune saved → /work/dlclarge2/alidemaa-text-control-orbis/orbis/finetuning/finetuned_orbis_AdaLN.ckpt
=== Job Finished ===
